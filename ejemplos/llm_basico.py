import os
import tiktoken
from dotenv import load_dotenv

# Carga las variables de entorno
load_dotenv(override=True)

# ConfiguraciÃ³n segÃºn el proveedor
API_HOST = os.getenv("API_HOST", "github")

# Seleccionar el modelo segÃºn el proveedor
if API_HOST == "azure":
    MODEL_NAME = os.environ["AZURE_OPENAI_DEPLOYMENT"]
elif API_HOST == "ollama":
    MODEL_NAME = os.environ["OLLAMA_MODEL"]
elif API_HOST == "github":
    MODEL_NAME = os.getenv("GITHUB_MODEL", "gpt-4o")
else:
    MODEL_NAME = os.environ["OPENAI_MODEL"]

# Texto de ejemplo
texto = "La inteligencia artificial estÃ¡ revolucionando el mundo."

try:
    # Intentar obtener el codificador especÃ­fico para el modelo
    encoding = tiktoken.encoding_for_model(MODEL_NAME)
    print(f"\nðŸ”µ Usando codificador para modelo {MODEL_NAME}")
except KeyError:
    # Si el modelo no tiene un codificador especÃ­fico, usar el codificador por defecto
    encoding = tiktoken.get_encoding("cl100k_base")
    print(f"\nðŸ”µ Usando codificador por defecto cl100k_base para {MODEL_NAME}")

# Tokenizar el texto
tokens = encoding.encode(texto)

print("\nðŸ“‘ Texto original:", texto)
print("ðŸ“Š NÃºmero de tokens:", len(tokens))
print("ðŸ“ƒ Tokens generados:", tokens)

# Decodificar nuevamente los tokens a texto
texto_decodificado = encoding.decode(tokens)
print("âœ… Texto decodificado:", texto_decodificado)